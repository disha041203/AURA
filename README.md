🧠 AURA — Adaptive, Unified, Responsible Assistant
AI-powered therapeutic chatbot for safe emotional support

💡 Overview
AURA is a research-driven chatbot designed to provide empathetic, ethical, and safe emotional assistance using AI.
It detects user emotions, generates supportive responses (CBT-inspired), and prevents manipulation or unsafe dialogue through real-time risk detection and safety escalation.

🎯 Objectives
Identify emotional tone and mental distress using NLP models.
Generate non-manipulative, empathetic responses.
Escalate high-risk interactions using C-SSRS–based protocols.
Promote safe and ethical human–AI interaction.

⚙️ Architecture
User Input 
 → Emotion & Risk Detection 
 → Response Generation (CBT + AI)
 → Safety Filter & Escalation 
 → Output
 
🧩 Tech Stack
Frontend: React / Flutter
Backend: FastAPI / Flask
AI Models: DistilBERT, RoBERTa, DialoGPT
Database: MongoDB / Firebase
Libraries: PyTorch, Hugging Face, Scikit-learn

📚 Datasets
DAIC-WOZ – Depression detection
ESConv – Empathetic conversations
C-SSRS – Suicide risk flow (for safety scripting)

🔒 Ethics & Safety
Transparent AI with explainable responses.
Built-in risk scoring and emergency referral system.
Logs anonymized, consent-based data only.
Not a substitute for therapy.

📊 Evaluation
F1-score for emotion classification
Human-rated empathy and safety
Accuracy of risk escalation
🧩 Keywords

AI for Social Good • Responsible AI • Affective Computing • Mental Health Technology
